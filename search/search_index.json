{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"example docs \u00b6 This is a basic example of documentation.","title":"Home"},{"location":"#example-docs","text":"This is a basic example of documentation.","title":"example docs"},{"location":"ADR-template/","text":"Title \u00b6 Decision Made: yes/no Decision Date: mo year Revisit Decision: yes/no Date mo year Revisit criteria: Decision Made: No, but open to revisiting Decision Date: 12/2018 Revisit Decision: Yes Revisit Date: July 2019 Revisit Criteria: If a developer is interested in Jest and has time or suggestions for fixing the speed issues, we should revisit this. Decision Makers: @githubusername, @githubsername tl;dr \u00b6 Summary of problem and decision History \u00b6 Dates, links to the PRs, notes- anything relevant to understand the decision making process / evolution. Important to list what you tried here so avoid retreading Pros \u00b6 upside Cons \u00b6 downside Decision \u00b6 Detailed reasoning about decision Example","title":"Title"},{"location":"ADR-template/#title","text":"Decision Made: yes/no Decision Date: mo year Revisit Decision: yes/no Date mo year Revisit criteria: Decision Made: No, but open to revisiting Decision Date: 12/2018 Revisit Decision: Yes Revisit Date: July 2019 Revisit Criteria: If a developer is interested in Jest and has time or suggestions for fixing the speed issues, we should revisit this. Decision Makers: @githubusername, @githubsername","title":"Title"},{"location":"ADR-template/#tldr","text":"Summary of problem and decision","title":"tl;dr"},{"location":"ADR-template/#history","text":"Dates, links to the PRs, notes- anything relevant to understand the decision making process / evolution. Important to list what you tried here so avoid retreading","title":"History"},{"location":"ADR-template/#pros","text":"upside","title":"Pros"},{"location":"ADR-template/#cons","text":"downside","title":"Cons"},{"location":"ADR-template/#decision","text":"Detailed reasoning about decision Example","title":"Decision"},{"location":"allstar/","text":"Allstar Configuration Files \u00b6 Allstar is a GitHub App ran by OpenSSF that helps set and enforce security policies for GitHub Repositories. Our repository uses a Repository Level Opt In Strategy . This means our repository contains our own .allstar directory to manage our security policies instead of using an organizational level .allstar directory. Inside the .allstar directory are several configuration files that outline our security policies and what Actions to take in the event of a security violation. Actions \u00b6 log : This is the default action, and actually takes place for all actions. All policy run results and details are logged. Logs are currently only visible to the app operator, plans to expose these are under discussion. issue : This action creates a GitHub issue. Only one issue is created per policy, and the text describes the details of the policy violation. If the issue is already open, it is pinged with a comment every 24 hours (not currently user configurable). Once the violation is addressed, the issue will be automatically closed by Allstar within 5-10 minutes. fix : This action is policy specific. The policy will make the changes to the GitHub settings to correct the policy violation. Not all policies will be able to support this (see below). Configuration Files in .allstar Directory \u00b6 allstar.yaml \u00b6 Purpose \u00b6 Configures whether our repository will opt in or opt out of using Allstar app for reporting security violations. Since our organization does not contain a .allstar directory, the default Allstar strategy for all repositories is assumed requiring each repository to opt in to manage security policies. binary_artifacts.yaml \u00b6 Purpose \u00b6 This policy uses check from scorecard . Remove the binary artifact from the repository to achieve compliance. As the scorecard results can be verbose, you may need to run scorecard itself to see all the detailed information. branch_protection.yaml \u00b6 Purpose \u00b6 This policy checks if our repository's branch protection settings match with the branch protection settings outlined in this file. outside.yaml \u00b6 Purpose \u00b6 By default this policy checks that only organizational members have administrative or push access to the repository. security.yaml \u00b6 Purpose \u00b6 This policy checks that the repository has a security policy file in SECURITY.md and it is not empty.","title":"Allstar Configuration Files"},{"location":"allstar/#allstar-configuration-files","text":"Allstar is a GitHub App ran by OpenSSF that helps set and enforce security policies for GitHub Repositories. Our repository uses a Repository Level Opt In Strategy . This means our repository contains our own .allstar directory to manage our security policies instead of using an organizational level .allstar directory. Inside the .allstar directory are several configuration files that outline our security policies and what Actions to take in the event of a security violation.","title":"Allstar Configuration Files"},{"location":"allstar/#actions","text":"log : This is the default action, and actually takes place for all actions. All policy run results and details are logged. Logs are currently only visible to the app operator, plans to expose these are under discussion. issue : This action creates a GitHub issue. Only one issue is created per policy, and the text describes the details of the policy violation. If the issue is already open, it is pinged with a comment every 24 hours (not currently user configurable). Once the violation is addressed, the issue will be automatically closed by Allstar within 5-10 minutes. fix : This action is policy specific. The policy will make the changes to the GitHub settings to correct the policy violation. Not all policies will be able to support this (see below).","title":"Actions"},{"location":"allstar/#configuration-files-in-allstar-directory","text":"","title":"Configuration Files in .allstar Directory"},{"location":"allstar/#allstaryaml","text":"","title":"allstar.yaml"},{"location":"allstar/#purpose","text":"Configures whether our repository will opt in or opt out of using Allstar app for reporting security violations. Since our organization does not contain a .allstar directory, the default Allstar strategy for all repositories is assumed requiring each repository to opt in to manage security policies.","title":"Purpose"},{"location":"allstar/#binary_artifactsyaml","text":"","title":"binary_artifacts.yaml"},{"location":"allstar/#purpose_1","text":"This policy uses check from scorecard . Remove the binary artifact from the repository to achieve compliance. As the scorecard results can be verbose, you may need to run scorecard itself to see all the detailed information.","title":"Purpose"},{"location":"allstar/#branch_protectionyaml","text":"","title":"branch_protection.yaml"},{"location":"allstar/#purpose_2","text":"This policy checks if our repository's branch protection settings match with the branch protection settings outlined in this file.","title":"Purpose"},{"location":"allstar/#outsideyaml","text":"","title":"outside.yaml"},{"location":"allstar/#purpose_3","text":"By default this policy checks that only organizational members have administrative or push access to the repository.","title":"Purpose"},{"location":"allstar/#securityyaml","text":"","title":"security.yaml"},{"location":"allstar/#purpose_4","text":"This policy checks that the repository has a security policy file in SECURITY.md and it is not empty.","title":"Purpose"},{"location":"backstage-update/","text":"Automated Backstage Update \u00b6 Backstage Update Workflow file Update Backstage Workflow Jobs \u00b6 check-for-existing-update \u00b6 Description: Before upgrade process begins, this job checks if there is currently an open pull request to update backstage. 1 2 3 4 5 6 7 Steps: - Checkout - Uses: [actions/checkout@v2](https://github.com/actions/checkout) - Checkout github repository so workflow can access it - Check for existing auto-update PR - Uses command line to make cURL request to GitHub API for all open pull requests using the \"auto-update-backstage\" branch - Stores url to open pull request as output link-pr \u00b6 Description: If there is an open pull request to update backstage, this job will output a link to the open pull request. 1 2 3 4 Steps: - Failed to Update Backstage - Uses: [actions/github-script@v3](https://github.com/actions/github-script) - Outputs the open pull request url retrieved from GitHub API request update-backstage \u00b6 Description: If there is no open pull request to update backstage, this job will create a branch, perform the upgrade process, and create a pull request with the new changes. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Steps: - Checkout - Uses: [actions/checkout@v2](https://github.com/actions/checkout) - Checkout github repository so workflow can access it - Install Dependencies - Uses yarn install to install dependencies for backstage upgrade process - Update Backstage - Runs npm script \"backstage-update\" which runs \"yarn backstage-cli versions:bump 2>&1 | tee backstage-update-log.txt\" - Compare Create App versions - Uses command line to get current version of \"@backstage/create-app\" from package.json and most recent version from NPM registry - Format PR body - Uses command line to format a summary of the update log to the pull request body - Set output variables - Sets variables for PR title and current date - Create Pull Request - Uses: [peter-evans/create-pull-request@v3](https://github.com/peter-evans/create-pull-request) - Creates pull request containing the changes from running \"backstage-update\" - Pull request body also contains a summary of the update log, outputs from the error log, current and most recent versions of \"@backstage/create-app\" and a link to the create-app changelog - Check outputs - Logs the number and url of the newly generated Pull Request","title":"Backstage Update"},{"location":"backstage-update/#automated-backstage-update","text":"Backstage Update Workflow file","title":"Automated Backstage Update"},{"location":"backstage-update/#update-backstage-workflow-jobs","text":"","title":"Update Backstage Workflow Jobs"},{"location":"backstage-update/#check-for-existing-update","text":"Description: Before upgrade process begins, this job checks if there is currently an open pull request to update backstage. 1 2 3 4 5 6 7 Steps: - Checkout - Uses: [actions/checkout@v2](https://github.com/actions/checkout) - Checkout github repository so workflow can access it - Check for existing auto-update PR - Uses command line to make cURL request to GitHub API for all open pull requests using the \"auto-update-backstage\" branch - Stores url to open pull request as output","title":"check-for-existing-update"},{"location":"backstage-update/#link-pr","text":"Description: If there is an open pull request to update backstage, this job will output a link to the open pull request. 1 2 3 4 Steps: - Failed to Update Backstage - Uses: [actions/github-script@v3](https://github.com/actions/github-script) - Outputs the open pull request url retrieved from GitHub API request","title":"link-pr"},{"location":"backstage-update/#update-backstage","text":"Description: If there is no open pull request to update backstage, this job will create a branch, perform the upgrade process, and create a pull request with the new changes. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Steps: - Checkout - Uses: [actions/checkout@v2](https://github.com/actions/checkout) - Checkout github repository so workflow can access it - Install Dependencies - Uses yarn install to install dependencies for backstage upgrade process - Update Backstage - Runs npm script \"backstage-update\" which runs \"yarn backstage-cli versions:bump 2>&1 | tee backstage-update-log.txt\" - Compare Create App versions - Uses command line to get current version of \"@backstage/create-app\" from package.json and most recent version from NPM registry - Format PR body - Uses command line to format a summary of the update log to the pull request body - Set output variables - Sets variables for PR title and current date - Create Pull Request - Uses: [peter-evans/create-pull-request@v3](https://github.com/peter-evans/create-pull-request) - Creates pull request containing the changes from running \"backstage-update\" - Pull request body also contains a summary of the update log, outputs from the error log, current and most recent versions of \"@backstage/create-app\" and a link to the create-app changelog - Check outputs - Logs the number and url of the newly generated Pull Request","title":"update-backstage"},{"location":"deployment/","text":"Automated workflows and infrastructure (WIP) \u00b6 This is a draft and does not represent current state. Application deployment \u00b6 TechDocs publication \u00b6 Jenkins environment variables \u00b6 Name Description TECHDOCS_S3_BUCKET_NAME AWS_ACCESS_KEY_ID AWS IAM user AWS_SECRET_ACCESS_KEY AWS_REGION Minimum IAM user access policy \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"VisualEditor0\", \"Effect\": \"Allow\", \"Action\": [ \"s3:PutObject\", ], \"Resource\": [ \"arn:aws:s3:::TECHDOCS_S3_BUCKET_NAME/*\", \"arn:aws:s3:::TECHDOCS_S3_BUCKET_NAME\" ] } ] } Backstage backend components \u00b6 Backstage backend container environment variables \u00b6 Name Description Privileges, permissions GITHUB_TOKEN GitHub Personal Access Token admin:org:read:org, user:read:user AUTH_GITHUB_CLIENT_ID GitHub OAuth AUTH_GITHUB_CLIENT_SECRET TECHDOCS_S3_BUCKET_NAME AWS_ACCESS_KEY_ID AWS IAM user AWS_SECRET_ACCESS_KEY AWS_REGION POSTGRES_USER PostgreSQL instance user SELECT, INSERT, UPDATE, DELETE, TRUNCATE, CREATE, CONNECT POSTGRES_HOST POSTGRES_PORT POSTGRES_PASSWORD Minimum IAM user policy \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"VisualEditor0\", \"Effect\": \"Allow\", \"Action\": [ \"s3:GetObject\", \"s3:ListBucket\" ], \"Resource\": [ \"arn:aws:s3:::TECHDOCS_S3_BUCKET_NAME/*\", \"arn:aws:s3:::TECHDOCS_S3_BUCKET_NAME\" ] } ] } Backstage frontend components \u00b6","title":"Deployment"},{"location":"deployment/#automated-workflows-and-infrastructure-wip","text":"This is a draft and does not represent current state.","title":"Automated workflows and infrastructure (WIP)"},{"location":"deployment/#application-deployment","text":"","title":"Application deployment"},{"location":"deployment/#techdocs-publication","text":"","title":"TechDocs publication"},{"location":"deployment/#jenkins-environment-variables","text":"Name Description TECHDOCS_S3_BUCKET_NAME AWS_ACCESS_KEY_ID AWS IAM user AWS_SECRET_ACCESS_KEY AWS_REGION","title":"Jenkins environment variables"},{"location":"deployment/#minimum-iam-user-access-policy","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"VisualEditor0\", \"Effect\": \"Allow\", \"Action\": [ \"s3:PutObject\", ], \"Resource\": [ \"arn:aws:s3:::TECHDOCS_S3_BUCKET_NAME/*\", \"arn:aws:s3:::TECHDOCS_S3_BUCKET_NAME\" ] } ] }","title":"Minimum IAM user access policy"},{"location":"deployment/#backstage-backend-components","text":"","title":"Backstage backend components"},{"location":"deployment/#backstage-backend-container-environment-variables","text":"Name Description Privileges, permissions GITHUB_TOKEN GitHub Personal Access Token admin:org:read:org, user:read:user AUTH_GITHUB_CLIENT_ID GitHub OAuth AUTH_GITHUB_CLIENT_SECRET TECHDOCS_S3_BUCKET_NAME AWS_ACCESS_KEY_ID AWS IAM user AWS_SECRET_ACCESS_KEY AWS_REGION POSTGRES_USER PostgreSQL instance user SELECT, INSERT, UPDATE, DELETE, TRUNCATE, CREATE, CONNECT POSTGRES_HOST POSTGRES_PORT POSTGRES_PASSWORD","title":"Backstage backend container environment variables"},{"location":"deployment/#minimum-iam-user-policy","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"VisualEditor0\", \"Effect\": \"Allow\", \"Action\": [ \"s3:GetObject\", \"s3:ListBucket\" ], \"Resource\": [ \"arn:aws:s3:::TECHDOCS_S3_BUCKET_NAME/*\", \"arn:aws:s3:::TECHDOCS_S3_BUCKET_NAME\" ] } ] }","title":"Minimum IAM user policy"},{"location":"deployment/#backstage-frontend-components","text":"","title":"Backstage frontend components"},{"location":"rfc-doc-generator/","text":"[RFC] Documentation Generator \u00b6 Summary : Allow documentation to be generated from code comments. Most documentation generators have a fairly similar syntax. So the main purpose of this RFC is to help decide between which syntax we would like more. I was able to find two generators that I think we should choose between, JSDoc and TypeDoc. Both of these generators have eslint-plugins that would allow us to require comments, and other nitpicking. They also allow us to generate documentation within GitHub Actions which is great. Like I said, the main difference is how the syntax will work with TypeScript. Note: Please feel free to let me know if there is another doc generator that you think we should consider. Background \u00b6 Why do we need a documentation generator? I think I speak for everyone when I say that documenting everything can become a huge pain and can take up time a lot of our time. A documentation generator can take our commented code and build a good looking HTML website, so long as we make good explanatory comments. Automating documentation is just another thing that can save us a ton of time and allow us to work on more important/fun features. Goal \u00b6 To decide on which documentation generator, JSDoc or TypeDoc, should be used when adding comments to the codebase. Similar to the summary both generators have similar syntax, eslint support, and GitHub Actions. The only real decision to make is which syntax we'd rather use. Generating documentation \u00b6 Both doc generators are able to run with a single CLI command. They can take inline arguments, or use a config file to determine where to look for files, and where it should output the generated documentation. For example if we want to generate docs from src using a specified config and then putting the generated docs into a docs folder. JSDoc can have plugins or other settings added to a jsdoc.json file as well. JSDoc -> /path/to/jsdoc src -r -c /path/to/my/conf.json -d docs Typedoc can use most of the TypeScript compiler options as well as the tsconfig file. TypeDoc -> typedoc --out docs src JSDoc \u00b6 JSDoc GitHub JSDoc + TypeScript Playground JSDoc has a lot of support and is quite popular. Documenting code can be incredibly easy and provide a lot of information about what's going on in a file. It's been a great way to add typing to JavaScript without using TypeScript. Supported Types: @type @param (or @arg or @argument) @returns (or @return) @typedef @callback @template @class (or @constructor) @this @extends (or @augments) @enum @deprecated In JSDoc types are listed within the comment. 1 2 3 4 5 6 7 8 9 10 11 12 13 /** @type {string} */ let s ; /** * @param {string} p1 - A string param. * @param {string=} p2 - An optional param (Closure syntax) * @param {string} [p3] - Another optional param (JSDoc syntax). * @param {string} [p4=\"test\"] - An optional param with a default value * @return {string} This is the result */ function stringsStringStrings ( p1 , p2 , p3 , p4 ) { // TODO } Unfortunately, JSDoc doesn't support TypeScript out of the box. There are some plugins like better-docs that can parse .ts | .tsx files. However, types aren't displayed correctly within the generated documentation. Meaning that we'd have to list out types within the comments and within the code. There is a way around it (I've done it before) but it requires some extra time and monkey-patching to get it to work correctly. TypeDoc \u00b6 TypeDoc GitHub It appears that TypeDoc can do everything that JSDoc can, but with out of the box support for TypeScript files. It also uses the tsconfig file to figure out where it should look for .ts | .tsx files. All comments are parsed as Markdown which adds additional styling for us! TypeDoc doesn't support all the tags that JSDoc does, but that's because it infers more information from the TypeScript code. So you are more than welcome to type regular TypeScript without needing to declare types within comments. 1 2 3 4 /** * @param text Comment for parameter \u00b4text\u00b4. */ function doSomething ( target : any , text : string ) : number ; Supported Tags: @param <param name> @typeParam <param name> or @template <param name> @return(s) @event @hidden and @ignore @internal @category @module @typedef, @callback @public, @protected, and @private TypeDoc can also support .js | .jsx files if the allowJS option is set to true in the tsconfig . Just note that it can't derive the type from the code so they would need to be explicitly stated within the comment. Recommendation \u00b6 Considering everything that we would want for a documentation generator. Linting Syntax Highlighting Doc Generation with CI/CD JavaScript/TypeScript Support Tags I believe that TypeDoc is the best choice considering it supports TypeScript out of the box. The syntax isn't very different from JSDoc, we just omit the types after the @param and @returns because it's written within the code! Techdocs \u00b6 We can specify another documentation folder so that we don't conflict with TechDocs. The only issue will be that GitHub Pages can only have one site per project. I don't think that there is a way for us to merge Techdocs + another site. We could possibly setup an account with Netlify or Heroku to publish the generated documentation. Or open another repository which we push to using GitHub Actions? eslint enforcement \u00b6 In my experience, I'm used to enforcing comments on All functions, just to describe the purpose, params, and return values. It helps devs to quickly understand how to use the function. It also helps to reveal if the function is doing too much. Anything else like Types, Interfaces, Variables have felt pretty self explanatory. When something does become convoluted, or can be confusing I'll usually add a comment explaining it's purpose. Errors Classes (Which should be avoided) Required for all Functions and include: A short description All parameters (If applicable) Returns (If applicable) Anything else is optional for me. We could include warnings for Types and Interfaces?","title":"RFC Doc Generator"},{"location":"rfc-doc-generator/#rfc-documentation-generator","text":"Summary : Allow documentation to be generated from code comments. Most documentation generators have a fairly similar syntax. So the main purpose of this RFC is to help decide between which syntax we would like more. I was able to find two generators that I think we should choose between, JSDoc and TypeDoc. Both of these generators have eslint-plugins that would allow us to require comments, and other nitpicking. They also allow us to generate documentation within GitHub Actions which is great. Like I said, the main difference is how the syntax will work with TypeScript. Note: Please feel free to let me know if there is another doc generator that you think we should consider.","title":"[RFC] Documentation Generator"},{"location":"rfc-doc-generator/#background","text":"Why do we need a documentation generator? I think I speak for everyone when I say that documenting everything can become a huge pain and can take up time a lot of our time. A documentation generator can take our commented code and build a good looking HTML website, so long as we make good explanatory comments. Automating documentation is just another thing that can save us a ton of time and allow us to work on more important/fun features.","title":"Background"},{"location":"rfc-doc-generator/#goal","text":"To decide on which documentation generator, JSDoc or TypeDoc, should be used when adding comments to the codebase. Similar to the summary both generators have similar syntax, eslint support, and GitHub Actions. The only real decision to make is which syntax we'd rather use.","title":"Goal"},{"location":"rfc-doc-generator/#generating-documentation","text":"Both doc generators are able to run with a single CLI command. They can take inline arguments, or use a config file to determine where to look for files, and where it should output the generated documentation. For example if we want to generate docs from src using a specified config and then putting the generated docs into a docs folder. JSDoc can have plugins or other settings added to a jsdoc.json file as well. JSDoc -> /path/to/jsdoc src -r -c /path/to/my/conf.json -d docs Typedoc can use most of the TypeScript compiler options as well as the tsconfig file. TypeDoc -> typedoc --out docs src","title":"Generating documentation"},{"location":"rfc-doc-generator/#jsdoc","text":"JSDoc GitHub JSDoc + TypeScript Playground JSDoc has a lot of support and is quite popular. Documenting code can be incredibly easy and provide a lot of information about what's going on in a file. It's been a great way to add typing to JavaScript without using TypeScript. Supported Types: @type @param (or @arg or @argument) @returns (or @return) @typedef @callback @template @class (or @constructor) @this @extends (or @augments) @enum @deprecated In JSDoc types are listed within the comment. 1 2 3 4 5 6 7 8 9 10 11 12 13 /** @type {string} */ let s ; /** * @param {string} p1 - A string param. * @param {string=} p2 - An optional param (Closure syntax) * @param {string} [p3] - Another optional param (JSDoc syntax). * @param {string} [p4=\"test\"] - An optional param with a default value * @return {string} This is the result */ function stringsStringStrings ( p1 , p2 , p3 , p4 ) { // TODO } Unfortunately, JSDoc doesn't support TypeScript out of the box. There are some plugins like better-docs that can parse .ts | .tsx files. However, types aren't displayed correctly within the generated documentation. Meaning that we'd have to list out types within the comments and within the code. There is a way around it (I've done it before) but it requires some extra time and monkey-patching to get it to work correctly.","title":"JSDoc"},{"location":"rfc-doc-generator/#typedoc","text":"TypeDoc GitHub It appears that TypeDoc can do everything that JSDoc can, but with out of the box support for TypeScript files. It also uses the tsconfig file to figure out where it should look for .ts | .tsx files. All comments are parsed as Markdown which adds additional styling for us! TypeDoc doesn't support all the tags that JSDoc does, but that's because it infers more information from the TypeScript code. So you are more than welcome to type regular TypeScript without needing to declare types within comments. 1 2 3 4 /** * @param text Comment for parameter \u00b4text\u00b4. */ function doSomething ( target : any , text : string ) : number ; Supported Tags: @param <param name> @typeParam <param name> or @template <param name> @return(s) @event @hidden and @ignore @internal @category @module @typedef, @callback @public, @protected, and @private TypeDoc can also support .js | .jsx files if the allowJS option is set to true in the tsconfig . Just note that it can't derive the type from the code so they would need to be explicitly stated within the comment.","title":"TypeDoc"},{"location":"rfc-doc-generator/#recommendation","text":"Considering everything that we would want for a documentation generator. Linting Syntax Highlighting Doc Generation with CI/CD JavaScript/TypeScript Support Tags I believe that TypeDoc is the best choice considering it supports TypeScript out of the box. The syntax isn't very different from JSDoc, we just omit the types after the @param and @returns because it's written within the code!","title":"Recommendation"},{"location":"rfc-doc-generator/#techdocs","text":"We can specify another documentation folder so that we don't conflict with TechDocs. The only issue will be that GitHub Pages can only have one site per project. I don't think that there is a way for us to merge Techdocs + another site. We could possibly setup an account with Netlify or Heroku to publish the generated documentation. Or open another repository which we push to using GitHub Actions?","title":"Techdocs"},{"location":"rfc-doc-generator/#eslint-enforcement","text":"In my experience, I'm used to enforcing comments on All functions, just to describe the purpose, params, and return values. It helps devs to quickly understand how to use the function. It also helps to reveal if the function is doing too much. Anything else like Types, Interfaces, Variables have felt pretty self explanatory. When something does become convoluted, or can be confusing I'll usually add a comment explaining it's purpose. Errors Classes (Which should be avoided) Required for all Functions and include: A short description All parameters (If applicable) Returns (If applicable) Anything else is optional for me. We could include warnings for Types and Interfaces?","title":"eslint enforcement"},{"location":"running-locally/","text":"Open a Codespace (preferred- work in progress) \u00b6 This repo is configured to run a production-like environment in a GitHub Codespace . Open a Codespace Run application: 1 yarn dev Install and run locally with Docker (work in progress) \u00b6 Prerequisites Install git Install Docker Desktop: Mac , Windows Run 1 sh local.sh start After the application runs for the first time, copy node_modules . While the application is running, run this is a separate terminal: 1 sh local.sh copy Caveats What does this do : This will install the application and its dependencies and then run the backend and frontend in separate containers. To ensure fast hot-reloading, node_modules and postgreSQL db are stored in a docker volume and your local source files are mounted into the container. Why do you need to copy after the first run : The application uses node_modules from Docker volume not your local files. Copy these locally so that dependencies resolve correctly in your editor. Install and run locally (TBD) \u00b6 Use nvm to install node You will need to update the Backstage configuration for running locally. Update these instructions if you try this out. app-config.yaml is used for Codespaces and it is merged with app-config.production.yaml in production environments. Supporting Codespaces is the priorty so consider that when changing the way configurations are organized.","title":"Running Locally"},{"location":"running-locally/#open-a-codespace-preferred-work-in-progress","text":"This repo is configured to run a production-like environment in a GitHub Codespace . Open a Codespace Run application: 1 yarn dev","title":"Open a Codespace (preferred- work in progress)"},{"location":"running-locally/#install-and-run-locally-with-docker-work-in-progress","text":"Prerequisites Install git Install Docker Desktop: Mac , Windows Run 1 sh local.sh start After the application runs for the first time, copy node_modules . While the application is running, run this is a separate terminal: 1 sh local.sh copy Caveats What does this do : This will install the application and its dependencies and then run the backend and frontend in separate containers. To ensure fast hot-reloading, node_modules and postgreSQL db are stored in a docker volume and your local source files are mounted into the container. Why do you need to copy after the first run : The application uses node_modules from Docker volume not your local files. Copy these locally so that dependencies resolve correctly in your editor.","title":"Install and run locally with Docker (work in progress)"},{"location":"running-locally/#install-and-run-locally-tbd","text":"Use nvm to install node You will need to update the Backstage configuration for running locally. Update these instructions if you try this out. app-config.yaml is used for Codespaces and it is merged with app-config.production.yaml in production environments. Supporting Codespaces is the priorty so consider that when changing the way configurations are organized.","title":"Install and run locally (TBD)"},{"location":"zero-install-adr/","text":"Yarn Zero Install ADR \u00b6 Decision Made: no Decision Date: 00/0000 Revisit Decision: yes Date 09/2021 Revisit criteria: Decision Made: No, but open to revisiting Decision Date: 09/2021 Revisit Decision: Yes, Revisit Date: September 2021 Revisit Criteria: When @backstage/cli replaces their @yarnpkg/lockfile parser usage with an updated package parser, @yarnpkg/parsers . Specifically, this file. Decision Makers: @kaemonisland, @rianfowler tl;dr \u00b6 CI/CD can take up to 10+ minutes to complete, specifically the build-containers action. Being able to use Yarn Zero-Install would allow us to cache dependencies thus lowering the run-time of CI/CD by a significant amount. History \u00b6 Yarn recently released a feature called Zero Install which allows packages to be cached. Yarn states the problem pretty clearly... 1 While Yarn does its best to guarantee that what works now will keep working, there's always the off chance that a future Yarn release will introduce a bug that will prevent you from installing your project. Or maybe your production environments will change and yarn install won't be able to write in the temporary directories anymore. Or maybe the network will fail and your packages won't be available anymore. Or maybe your credentials will rotate and you will start getting authentication issues. Or ... so many things can go wrong, and not all of them are things we can control. Pros \u00b6 Fast Caching packages will allow packages to be installed much faster than the current yarn install . ALso, when updating packages, Yarn 2 will change exactly one file for each updated package. Plug N Play Removes the need for node modules completely. If we were able to get Zero Install + Plug n Play our install time would be almost instantaneous. https://yarnpkg.com/features/pnp#fixing-node_modules Small File Size To give you an idea, a node_modules folder of 135k uncompressed files (for a total of 1.2GB) gives a Yarn cache of 2k binary archives (for a total of 139MB). Git simply cannot support the former, while the latter is perfectly fine. Secure Projects accepting PRs from external users will have to be careful that the PRs affecting the package archives are legit (since it would otherwise be possible to a malicious user to send a PR for a new dependency after having altered its archive content). yarn install --check-cache This way Yarn will re-download the package files from whatever their remote location would be and will report any mismatching checksum. Cons \u00b6 Configuration Zero install can get confusing when configuring zero install for Lerna + TypeScript. Additional configuration settings will need to be applied in order for the linter to recognize the package locations. Plugins Decision \u00b6 Adding Yarn Zero Installs will allow CI/CD and local development to get running faster. Currently, it takes about 2+ minutes to install all the necessary packages by running yarn install . Zero Install should allow us to cut that time down to less than one minute by caching packages. If we decide to also setup Plug N Play, we could cut that time down to almost instantaneous speeds. The only thing that is holding us back is @backstage/cli which uses an incompatible package, @yarnpkg/lockfile , to parse the yarn.lock file.","title":"Yarn Zero Install(ADR)"},{"location":"zero-install-adr/#yarn-zero-install-adr","text":"Decision Made: no Decision Date: 00/0000 Revisit Decision: yes Date 09/2021 Revisit criteria: Decision Made: No, but open to revisiting Decision Date: 09/2021 Revisit Decision: Yes, Revisit Date: September 2021 Revisit Criteria: When @backstage/cli replaces their @yarnpkg/lockfile parser usage with an updated package parser, @yarnpkg/parsers . Specifically, this file. Decision Makers: @kaemonisland, @rianfowler","title":"Yarn Zero Install ADR"},{"location":"zero-install-adr/#tldr","text":"CI/CD can take up to 10+ minutes to complete, specifically the build-containers action. Being able to use Yarn Zero-Install would allow us to cache dependencies thus lowering the run-time of CI/CD by a significant amount.","title":"tl;dr"},{"location":"zero-install-adr/#history","text":"Yarn recently released a feature called Zero Install which allows packages to be cached. Yarn states the problem pretty clearly... 1 While Yarn does its best to guarantee that what works now will keep working, there's always the off chance that a future Yarn release will introduce a bug that will prevent you from installing your project. Or maybe your production environments will change and yarn install won't be able to write in the temporary directories anymore. Or maybe the network will fail and your packages won't be available anymore. Or maybe your credentials will rotate and you will start getting authentication issues. Or ... so many things can go wrong, and not all of them are things we can control.","title":"History"},{"location":"zero-install-adr/#pros","text":"Fast Caching packages will allow packages to be installed much faster than the current yarn install . ALso, when updating packages, Yarn 2 will change exactly one file for each updated package. Plug N Play Removes the need for node modules completely. If we were able to get Zero Install + Plug n Play our install time would be almost instantaneous. https://yarnpkg.com/features/pnp#fixing-node_modules Small File Size To give you an idea, a node_modules folder of 135k uncompressed files (for a total of 1.2GB) gives a Yarn cache of 2k binary archives (for a total of 139MB). Git simply cannot support the former, while the latter is perfectly fine. Secure Projects accepting PRs from external users will have to be careful that the PRs affecting the package archives are legit (since it would otherwise be possible to a malicious user to send a PR for a new dependency after having altered its archive content). yarn install --check-cache This way Yarn will re-download the package files from whatever their remote location would be and will report any mismatching checksum.","title":"Pros"},{"location":"zero-install-adr/#cons","text":"Configuration Zero install can get confusing when configuring zero install for Lerna + TypeScript. Additional configuration settings will need to be applied in order for the linter to recognize the package locations. Plugins","title":"Cons"},{"location":"zero-install-adr/#decision","text":"Adding Yarn Zero Installs will allow CI/CD and local development to get running faster. Currently, it takes about 2+ minutes to install all the necessary packages by running yarn install . Zero Install should allow us to cut that time down to less than one minute by caching packages. If we decide to also setup Plug N Play, we could cut that time down to almost instantaneous speeds. The only thing that is holding us back is @backstage/cli which uses an incompatible package, @yarnpkg/lockfile , to parse the yarn.lock file.","title":"Decision"}]}